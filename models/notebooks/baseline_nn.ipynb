{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833eebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "README\n",
    "\n",
    "Directory Structure\n",
    "\n",
    "CS3244-Twemoji\n",
    "├── Dataset\n",
    "│   ├── train_bert_embeddings.npy\n",
    "│   ├── valid_bert_embeddings.npy\n",
    "│   ├── test_bert_embeddings.npy\n",
    "│   ├── train_with_bert_embeddings.csv\n",
    "│   ├── valid_with_bert_embeddings.csv\n",
    "│   └── test_with_bert_embeddings.csv\n",
    "│\n",
    "├── src\n",
    "│   ├── main.ipynb (this notebook)\n",
    "│   └── eda.ipynb\n",
    "│\n",
    "└── venv # ignore this\n",
    "\n",
    "NB : Main work is solely in the structuring of your directory\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "FINAL_NOTE:\n",
    "\n",
    "After testing by Nigel (big thanks to nigel), \n",
    "the baseline model will use the following:\n",
    "\n",
    "- Embedder : BERT Embedding (without any further preprocessing and feature engineering)\n",
    "- First Layer Dense Unit    : 64 neuron, activation function : ReLU\n",
    "- First Dropout Rate        : 0.00\n",
    "- Second Layer Dense Unit   : 32 neuron, activation function : ReLU\n",
    "- Second Dropout Rate       : 0.00\n",
    "- Learning Rate             : 0.001\n",
    "- Optimizer                 : Stochastic Gradient Descent (SGD)\n",
    "- Training Batch Size       : 16\n",
    "- Loss Function             : Sparse Categorical Cross Entropy\n",
    "- Metrics                   : Accuracy\n",
    "- Epochs                    : 15\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6a98a",
   "metadata": {},
   "source": [
    "# Package Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6248e2-c029-4984-8642-060669fc204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13284a3",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98815bb0-51a0-4ef1-b271-5042a1b0fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embed_path = os.path.join(os.path.dirname(os.getcwd()), \"Dataset\", \"train_bert_embeddings.npy\")\n",
    "valid_embed_path = os.path.join(os.path.dirname(os.getcwd()), \"Dataset\", \"valid_bert_embeddings.npy\")\n",
    "test_embed_path = os.path.join(os.path.dirname(os.getcwd()), \"Dataset\", \"test_bert_embeddings.npy\")\n",
    "train_labels_path = os.path.join(os.path.dirname(os.getcwd()), \"Dataset\", \"train_with_bert_embeddings.csv\")\n",
    "valid_labels_path = os.path.join(os.path.dirname(os.getcwd()), \"Dataset\", \"valid_with_bert_embeddings.csv\")\n",
    "test_labels_path = os.path.join(os.path.dirname(os.getcwd()), \"Dataset\", \"test_with_bert_embeddings.csv\")\n",
    "\n",
    "train_embeddings = np.load(train_embed_path)\n",
    "valid_embeddings = np.load(valid_embed_path)\n",
    "test_embeddings = np.load(test_embed_path)\n",
    "train_labels = pd.read_csv(train_labels_path)\n",
    "valid_labels = pd.read_csv(valid_labels_path)\n",
    "test_labels = pd.read_csv(test_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebcf333a-ee96-4fde-bd38-e7664ddd802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (133999, 768), train_Y shape: (133999,)\n",
      "valid_X shape: (17223, 768), valid_Y shape: (17223,)\n",
      "test_X shape: (17063, 768), test_Y shape: (17063,)\n"
     ]
    }
   ],
   "source": [
    "# Ensure indices are integers\n",
    "train_indices = train_labels['embedding_index'].values.astype(int)\n",
    "valid_indices = valid_labels['embedding_index'].values.astype(int)\n",
    "test_indices = test_labels['embedding_index'].values.astype(int)\n",
    "\n",
    "# Extract embeddings using indices\n",
    "train_X = train_embeddings[train_indices]\n",
    "valid_X = valid_embeddings[valid_indices]\n",
    "test_X = test_embeddings[test_indices]\n",
    "\n",
    "# Extract labels (assuming 'label' column contains integer class labels)\n",
    "train_Y = train_labels['label'].values.astype(int)\n",
    "valid_Y = valid_labels['label'].values.astype(int)\n",
    "test_Y = test_labels['label'].values.astype(int)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"train_X shape: {train_X.shape}, train_Y shape: {train_Y.shape}\")\n",
    "print(f\"valid_X shape: {valid_X.shape}, valid_Y shape: {valid_Y.shape}\")\n",
    "print(f\"test_X shape: {test_X.shape}, test_Y shape: {test_Y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6958360",
   "metadata": {},
   "source": [
    "# Model Building and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4332f50f-34e2-4c77-8c6d-631588bf857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 435us/step - accuracy: 0.3733 - loss: 1.4114 - val_accuracy: 0.4281 - val_loss: 1.3191\n",
      "Epoch 2/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 404us/step - accuracy: 0.4266 - loss: 1.3167 - val_accuracy: 0.4349 - val_loss: 1.3069\n",
      "Epoch 3/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395us/step - accuracy: 0.4350 - loss: 1.3039 - val_accuracy: 0.4373 - val_loss: 1.2991\n",
      "Epoch 4/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 394us/step - accuracy: 0.4423 - loss: 1.2906 - val_accuracy: 0.4413 - val_loss: 1.2937\n",
      "Epoch 5/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 389us/step - accuracy: 0.4462 - loss: 1.2819 - val_accuracy: 0.4412 - val_loss: 1.2945\n",
      "Epoch 6/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 391us/step - accuracy: 0.4536 - loss: 1.2744 - val_accuracy: 0.4439 - val_loss: 1.2890\n",
      "Epoch 7/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 394us/step - accuracy: 0.4528 - loss: 1.2701 - val_accuracy: 0.4457 - val_loss: 1.2886\n",
      "Epoch 8/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 388us/step - accuracy: 0.4561 - loss: 1.2658 - val_accuracy: 0.4449 - val_loss: 1.2928\n",
      "Epoch 9/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 394us/step - accuracy: 0.4585 - loss: 1.2622 - val_accuracy: 0.4405 - val_loss: 1.2946\n",
      "Epoch 10/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 393us/step - accuracy: 0.4590 - loss: 1.2574 - val_accuracy: 0.4402 - val_loss: 1.2958\n",
      "Epoch 11/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 391us/step - accuracy: 0.4645 - loss: 1.2518 - val_accuracy: 0.4445 - val_loss: 1.2831\n",
      "Epoch 12/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 390us/step - accuracy: 0.4684 - loss: 1.2430 - val_accuracy: 0.4496 - val_loss: 1.2811\n",
      "Epoch 13/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 392us/step - accuracy: 0.4709 - loss: 1.2406 - val_accuracy: 0.4455 - val_loss: 1.2805\n",
      "Epoch 14/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 396us/step - accuracy: 0.4724 - loss: 1.2362 - val_accuracy: 0.4476 - val_loss: 1.2846\n",
      "Epoch 15/15\n",
      "\u001b[1m8375/8375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 390us/step - accuracy: 0.4753 - loss: 1.2318 - val_accuracy: 0.4400 - val_loss: 1.2972\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture Hyperparameters\n",
    "input_shape = train_X.shape[1]\n",
    "dense_1_units = 64\n",
    "dense_1_activation = \"relu\"  \n",
    "dropout_1_rate = 0.0\n",
    "dense_2_units = 32\n",
    "dense_2_activation = \"relu\"  \n",
    "dropout_2_rate = 0.0\n",
    "output_units = len(np.unique(train_Y))\n",
    "output_activation = \"softmax\"\n",
    "\n",
    "# Training Hyperparameters\n",
    "optimizer = \"sgd\"\n",
    "learning_rate = 0.001\n",
    "loss_function = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "# Training Parameters\n",
    "batch_size = 16\n",
    "epochs = 15\n",
    "validation_data = (valid_X, valid_Y)\n",
    "\n",
    "# Model Compilation & Training\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(input_shape,)),\n",
    "    tf.keras.layers.Dense(dense_1_units, activation = dense_1_activation),\n",
    "    tf.keras.layers.Dropout(dropout_1_rate),\n",
    "    tf.keras.layers.Dense(dense_2_units, activation = dense_2_activation),\n",
    "    tf.keras.layers.Dropout(dropout_2_rate),\n",
    "    tf.keras.layers.Dense(output_units, activation = output_activation)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=metrics)\n",
    "\n",
    "history = model.fit(train_X, train_Y, validation_data=validation_data,\n",
    "                    epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3542e442-59ac-4982-9d79-7ca0380e1722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/534\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.4688 - loss: 1.4805"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.4764 - loss: 1.2285\n",
      "Test Accuracy: 0.4428\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253us/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_X, test_Y)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = model.predict(test_X)\n",
    "test_predicted_classes = np.argmax(test_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83d66e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"baseline_nn_weights.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
