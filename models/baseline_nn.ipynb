{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b6248e2-c029-4984-8642-060669fc204e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98815bb0-51a0-4ef1-b271-5042a1b0fdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_embeddings from bert embedding, dk why i stored in such a weird way lol but i blame gpt\n",
    "train_embeddings = np.load('./dataset/train_bert_embeddings.npy')\n",
    "valid_embeddings = np.load('./dataset/valid_bert_embeddings.npy')\n",
    "test_embeddings = np.load('./dataset/test_bert_embeddings.npy')\n",
    "train_labels = pd.read_csv(\"./dataset/train_with_bert_embeddings.csv\")\n",
    "valid_labels = pd.read_csv(\"./dataset/valid_with_bert_embeddings.csv\")\n",
    "test_labels = pd.read_csv(\"./dataset/test_with_bert_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebcf333a-ee96-4fde-bd38-e7664ddd802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X shape: (133999, 768), train_Y shape: (133999,)\n",
      "valid_X shape: (17223, 768), valid_Y shape: (17223,)\n",
      "test_X shape: (17063, 768), test_Y shape: (17063,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure indices are integers\n",
    "train_indices = train_labels['embedding_index'].values.astype(int)\n",
    "valid_indices = valid_labels['embedding_index'].values.astype(int)\n",
    "test_indices = test_labels['embedding_index'].values.astype(int)\n",
    "\n",
    "# Extract embeddings using indices\n",
    "train_X = train_embeddings[train_indices]\n",
    "valid_X = valid_embeddings[valid_indices]\n",
    "test_X = test_embeddings[test_indices]\n",
    "\n",
    "# Extract labels (assuming 'label' column contains integer class labels)\n",
    "train_Y = train_labels['label'].values.astype(int)\n",
    "valid_Y = valid_labels['label'].values.astype(int)\n",
    "test_Y = test_labels['label'].values.astype(int)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f\"train_X shape: {train_X.shape}, train_Y shape: {train_Y.shape}\")\n",
    "print(f\"valid_X shape: {valid_X.shape}, valid_Y shape: {valid_Y.shape}\")\n",
    "print(f\"test_X shape: {test_X.shape}, test_Y shape: {test_Y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4332f50f-34e2-4c77-8c6d-631588bf857e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.3675 - loss: 1.4150 - val_accuracy: 0.4290 - val_loss: 1.3182\n",
      "Epoch 2/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.4153 - loss: 1.3394 - val_accuracy: 0.4371 - val_loss: 1.3105\n",
      "Epoch 3/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.4238 - loss: 1.3233 - val_accuracy: 0.4356 - val_loss: 1.3147\n",
      "Epoch 4/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.4258 - loss: 1.3165 - val_accuracy: 0.4379 - val_loss: 1.3014\n",
      "Epoch 5/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.4318 - loss: 1.3094 - val_accuracy: 0.4352 - val_loss: 1.3004\n",
      "Epoch 6/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 989us/step - accuracy: 0.4381 - loss: 1.3024 - val_accuracy: 0.4443 - val_loss: 1.2928\n",
      "Epoch 7/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.4379 - loss: 1.2980 - val_accuracy: 0.4407 - val_loss: 1.2969\n",
      "Epoch 8/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.4410 - loss: 1.2951 - val_accuracy: 0.4419 - val_loss: 1.2902\n",
      "Epoch 9/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.4426 - loss: 1.2866 - val_accuracy: 0.4425 - val_loss: 1.2933\n",
      "Epoch 10/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.4438 - loss: 1.2879 - val_accuracy: 0.4466 - val_loss: 1.2915\n",
      "Epoch 11/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.4448 - loss: 1.2807 - val_accuracy: 0.4461 - val_loss: 1.2924\n",
      "Epoch 12/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.4447 - loss: 1.2808 - val_accuracy: 0.4424 - val_loss: 1.2903\n",
      "Epoch 13/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.4456 - loss: 1.2769 - val_accuracy: 0.4412 - val_loss: 1.2918\n",
      "Epoch 14/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 989us/step - accuracy: 0.4494 - loss: 1.2731 - val_accuracy: 0.4508 - val_loss: 1.2846\n",
      "Epoch 15/15\n",
      "\u001b[1m4188/4188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.4474 - loss: 1.2729 - val_accuracy: 0.4534 - val_loss: 1.2835\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Model Architecture Hyperparameters\n",
    "input_shape = train_X.shape[1]  # Number of features in embeddings\n",
    "dense_1_units = 128  # Neurons in first dense layer\n",
    "dense_1_activation = \"relu\"  \n",
    "dropout_1_rate = 0.3  # Dropout rate for first dropout layer\n",
    "dense_2_units = 64  # Neurons in second dense layer\n",
    "dense_2_activation = \"relu\"  \n",
    "dropout_2_rate = 0.3  # Dropout rate for second dropout layer\n",
    "output_units = len(np.unique(train_Y))  # Number of classes in output layer\n",
    "output_activation = \"softmax\"  # Activation for classification\n",
    "\n",
    "# Training Hyperparameters\n",
    "optimizer = \"adam\"  # Optimizer choice\n",
    "learning_rate = 0.001  # Learning rate\n",
    "loss_function = \"sparse_categorical_crossentropy\"  # Loss function for classification\n",
    "metrics = [\"accuracy\"]  # Metrics to track\n",
    "\n",
    "# Training Parameters\n",
    "batch_size = 32  # Batch size for training\n",
    "epochs = 15  # Number of epochs to train\n",
    "validation_data = (valid_X, valid_Y)  # Validation data\n",
    "\n",
    "# Model Compilation & Training\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(input_shape,)),\n",
    "    layers.Dense(dense_1_units, activation=dense_1_activation),\n",
    "    layers.Dropout(dropout_1_rate),\n",
    "    layers.Dense(dense_2_units, activation=dense_2_activation),\n",
    "    layers.Dropout(dropout_2_rate),\n",
    "    layers.Dense(output_units, activation=output_activation)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=metrics)\n",
    "\n",
    "history = model.fit(train_X, train_Y, validation_data=validation_data,\n",
    "                    epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3542e442-59ac-4982-9d79-7ca0380e1722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - accuracy: 0.4965 - loss: 1.2222\n",
      "Test Accuracy: 0.4448\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_X, test_Y)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = model.predict(test_X)\n",
    "test_predicted_classes = np.argmax(test_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b3ae4a-070d-405c-a7c8-8ef032c95ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
