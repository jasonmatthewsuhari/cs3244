{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Twemoji Classifier ‚Äì CS3244 AY24/25 Sem 2\n",
    "\n",
    "**Group Members:**  \n",
    "- Jason Matthew Suhari  \n",
    "- Bryan Castorius Halim  \n",
    "- Nigel Eng Wee Kiat  \n",
    "- Muhammad Salman Al Farisi  \n",
    "- Ng Jia Hao Sherwin  \n",
    "- Ryan Justyn\n",
    "\n",
    "This notebook builds and evaluates baseline models for classifying tweets into emojis using the Twemoji dataset. It's the main entry point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from src.models.log_reg import get_log_reg_model\n",
    "from src.models.random_forest import get_random_forest_model\n",
    "from src.models.svm import get_svm_model\n",
    "from src.models.cnn import get_cnn_model\n",
    "from src.models.simple_nn import get_simple_nn\n",
    "\n",
    "from src.preprocessing import preprocess_texts\n",
    "from src.utils import load_data, vectorize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Create data/ folder if it doesn't exist\n",
    "Path(\"data/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load list of .npy file URLs\n",
    "with open(\"data/urls.txt\", \"r\") as f:\n",
    "    urls = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "# Dictionary to store loaded numpy arrays\n",
    "loaded_data = {}\n",
    "\n",
    "for url in urls:\n",
    "    filename = os.path.basename(url)\n",
    "    filepath = os.path.join(\"data\", filename)\n",
    "\n",
    "    # Skip download if file already exists\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"üì• Downloading {filename} from S3...\")\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            with open(filepath, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to download {filename}: {response.status_code}\")\n",
    "            continue\n",
    "    else:\n",
    "        print(f\"‚úÖ {filename} already exists. Skipping download.\")\n",
    "\n",
    "    # Load .npy file\n",
    "    print(f\"üì¶ Loading {filename}...\")\n",
    "    loaded_data[filename] = np.load(filepath)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
