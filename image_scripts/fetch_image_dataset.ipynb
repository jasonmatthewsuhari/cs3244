{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8812dc1-1426-4c56-bca0-60b20540f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "from collections import Counter\n",
    "import time"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ccf769ee-880f-405b-85dc-56be2c4a60f2",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Find the top most occurring emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6257f09a-c641-4822-862e-dfd835c7d393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 12 most frequent emojis (ignoring duplicates within rows):\n",
      "üòç: [1392]: 70040\n",
      "‚ù§: [186]: 68010\n",
      "üòÇ: [1381]: 52175\n",
      "üíï: [1107]: 35765\n",
      "üòä: [1389]: 27146\n",
      "üòò: [1403]: 24352\n",
      "üèº: [762]: 23162\n",
      "üèª: [761]: 20895\n",
      "‚ú®: [174]: 20757\n",
      "üî•: [1255]: 20025\n",
      "üíô: [1111]: 18375\n",
      "üíñ: [1108]: 18081\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Run locally (different from repository data folder)\n",
    "# Change to train/valid/test accordingly\n",
    "df = pd.read_csv(\"dataset/img_train_plaintext.txt\", sep=\"\\t\", dtype={\"id\": str, \"annotations\": str})\n",
    "\n",
    "emoji_df = pd.read_csv(\"data/emoji_map.csv\")\n",
    "emoji_list = emoji_df[\"Unnamed: 0\"].tolist()\n",
    "emoji_map = {str(i): emoji for i, emoji in enumerate(emoji_list)}\n",
    "\n",
    "all_annotation_ids = []\n",
    "\n",
    "for ann in df['annotations'].dropna():\n",
    "    ids = ann.split(\",\")\n",
    "    unique_ids = set(ids)\n",
    "    all_annotation_ids.extend(unique_ids)\n",
    "\n",
    "counter = Counter(all_annotation_ids)\n",
    "\n",
    "top_12 = counter.most_common(12)\n",
    "\n",
    "print(\"Top 12 most frequent emojis (ignoring duplicates within rows):\")\n",
    "for ann_id, count in top_12:\n",
    "    emoji = emoji_map.get(ann_id, f\"[{ann_id}]\") \n",
    "    print(f\"{emoji}: [{ann_id}]: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc244b-dbd2-438a-9dd8-31461ebcc4fb",
   "metadata": {},
   "source": [
    "Remove weird emojis which are modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f571fc-5f84-4eb0-934d-783c6327b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 12 most frequent emojis (ignoring weird modifiers):\n",
      "üòç: 70040\n",
      "‚ù§: 68010\n",
      "üòÇ: 52175\n",
      "üíï: 35765\n",
      "üòä: 27146\n",
      "üòò: 24352\n",
      "‚ú®: 20757\n",
      "üî•: 20025\n",
      "üíô: 18375\n",
      "üíñ: 18081\n",
      "üò≠: 17104\n",
      "üëå: 16257\n"
     ]
    }
   ],
   "source": [
    "skip_ids = {str(i) for i in range(761, 766)} # Skin tone modifiers\n",
    "\n",
    "filtered_counter = Counter({k: v for k, v in counter.items() if k not in skip_ids})\n",
    "\n",
    "top_12 = filtered_counter.most_common(12)\n",
    "\n",
    "print(\"Top 12 most frequent emojis (ignoring weird modifiers):\")\n",
    "for ann_id, count in top_12:\n",
    "    emoji = emoji_map.get(ann_id, f\"[{ann_id}]\")\n",
    "    print(f\"{emoji}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ce93136-bf50-4588-9dab-069ee372832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1392, 186, 1381, 1107, 1389, 1403, 174, 1255, 1111, 1108, 1424, 883]\n"
     ]
    }
   ],
   "source": [
    "top_12_ids = [int(ann_id) for ann_id, count in top_12]\n",
    "print(top_12_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d74d8d-70f9-4e32-99f8-b6fe89bac196",
   "metadata": {},
   "source": [
    "Create a new CSV that only contains entry with the top 12 emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c248b37a-6911-4575-99ad-8445b5b0c2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 12 annotation IDs (after filtering): ['1392', '186', '1381', '1107', '1389', '1403', '174', '1255', '1111', '1108', '1424', '883']\n"
     ]
    }
   ],
   "source": [
    "# Change to train/valid/test accordingly\n",
    "df = pd.read_csv(\"dataset/img_train_plaintext.txt\", sep=\"\\t\", dtype={\"id\": str, \"annotations\": str})\n",
    "\n",
    "all_annotation_ids = []\n",
    "for ann in df['annotations'].dropna():\n",
    "    ids = [a.strip() for a in ann.split(\",\")]\n",
    "    unique_ids = set(ids)\n",
    "    all_annotation_ids.extend(unique_ids)\n",
    "\n",
    "counter = Counter(all_annotation_ids)\n",
    "\n",
    "skip_ids = {str(i) for i in range(761, 766)}\n",
    "\n",
    "filtered_counter = Counter({k: v for k, v in counter.items() if k not in skip_ids})\n",
    "\n",
    "top_12 = filtered_counter.most_common(12)\n",
    "top_12_ids = [ann_id for ann_id, count in top_12]\n",
    "print(\"Top 12 annotation IDs (after filtering):\", top_12_ids)\n",
    "\n",
    "def contains_top_annotation(ann_str):\n",
    "    if pd.isna(ann_str):\n",
    "        return False\n",
    "    ids = [a.strip() for a in ann_str.split(\",\")]\n",
    "    return any(a in top_12_ids for a in ids)\n",
    "\n",
    "filtered_df = df[df['annotations'].apply(contains_top_annotation)]\n",
    "\n",
    "# Change to train/valid/test accordingly\n",
    "filtered_df.to_csv(\"dataset/img_train_top12.csv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234a34c-7d99-4e66-bff7-827d3d6d16f7",
   "metadata": {},
   "source": [
    "Download valid images (accessible URL) from the dataset containing the Top 12 emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7516d9a6-2d7f-4f21-871c-57825d0d0cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# Load CSV of the newly Top 12 CSV\n",
    "# Change to train/valid/test accordingly\n",
    "df = pd.read_csv(\"dataset/img_train_top12.csv\", sep=\"\\t\", dtype={\"id\": str})\n",
    "\n",
    "def fetch_image_data(row):\n",
    "    url = row['imgid']\n",
    "    new_row = row.copy()  \n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        new_row['image'] = img\n",
    "        new_row['has_image'] = True\n",
    "    except Exception as e:\n",
    "        #print(f\"Error fetching image {row['id']}: {e}\")\n",
    "        new_row['image'] = None\n",
    "        new_row['has_image'] = False\n",
    "    return new_row\n",
    "\n",
    "max_workers = os.cpu_count() * 10\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    results = list(executor.map(fetch_image_data, df.to_dict(orient=\"records\")))\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "result_df = result_df[result_df[\"has_image\"]].copy()\n",
    "result_df.reset_index(drop=True, inplace=True)\n",
    "# Change to train/valid/test accordingly\n",
    "result_df.drop(columns=[\"image\"]).to_csv(\"img_train.csv\", index=False)\n",
    "\n",
    "# Store individual images in this folder, due to large size, we do not push it to our repository\n",
    "img_folder = \"img_train\"\n",
    "if not os.path.exists(img_folder):\n",
    "    os.makedirs(img_folder)\n",
    "\n",
    "def save_compressed_image(row):\n",
    "    if row[\"has_image\"] and row[\"image\"] is not None:\n",
    "        file_id = row[\"id\"].lstrip(\"'\")\n",
    "        file_path = os.path.join(img_folder, f\"{file_id}.jpg\")\n",
    "        try:\n",
    "            row[\"image\"].save(file_path, format=\"JPEG\", quality=40, optimize=True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving image for id {file_id}: {e}\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    executor.map(save_compressed_image, result_df.to_dict(orient=\"records\"))\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3402c1",
   "metadata": {},
   "source": [
    "Modify and map the annotation ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b7b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train_AfterPreprocessing/output_valid_images.csv\")\n",
    "df = df.drop(columns=[\"has_image\", \"imgid\"]) # To make it look cleaner\n",
    "\n",
    "top_12_ids.sort()\n",
    "\n",
    "# Map top 12 id into value 0 to 11\n",
    "id_to_label = {cls_id: idx for idx, cls_id in enumerate(top_12_ids)}\n",
    "\n",
    "for cls_id, label in id_to_label.items():\n",
    "    print(f\"{cls_id}: {label}\")\n",
    "\n",
    "def map_annotations(annotation_str):\n",
    "    ids = [int(x) for x in annotation_str.split(',')]\n",
    "    filtered = [str(id_to_label[i]) for i in ids if i in id_to_label]\n",
    "    return ','.join(filtered)\n",
    "\n",
    "df['annotations'] = df['annotations'].apply(map_annotations)\n",
    "\n",
    "df.to_csv(\"Train_AfterPreprocessing/img_train.csv\", index=False) # Change to train/valid/test accordingly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
